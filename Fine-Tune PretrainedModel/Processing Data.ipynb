{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f2bf02-3e76-431e-aa4e-db9b5b7a4a72",
   "metadata": {},
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ffb7265-15bb-47ed-b01a-f0a69983b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a87f5b8-7583-42a4-ba27-0c26028e41fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets=load_dataset(\"glue\",\"mrpc\")# caches the dataset, by default in ~/.cache/huggingface/datasets\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70c1377-825d-4f33-b320-12f1854b5538",
   "metadata": {},
   "source": [
    "> 10 datasets composing the GLUE benchmark, which is an academic benchmark that is used to measure the performance of ML models across 10 different text classification tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8757b3a4-39cd-480f-9b35-df0ab7e0a289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset=raw_datasets[\"train\"]\n",
    "raw_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "312b4501-cf08-485a-86ef-ed96bea80251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f20c1d2-768c-4b9d-a0c6-8fdce71d7d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "checkpoint=\"bert-base-uncased\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5faf0-0467-4df7-87bc-bc4a2b98ae77",
   "metadata": {},
   "source": [
    ">We need to handle the two sequences as a pair,  tokenizer can also take a pair of sequences and prepare it the way our BERT model expects: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cd46991-4fa9-449a-9b7d-993f3565085c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2023, 2003, 1996, 2034, 6251, 1012, 102, 2023, 2003, 1996, 2117, 2028, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"This is the first sentence.\", \"This is the second one.\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a66ad6c-9c78-4795-9f82-de98f3ec4849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'first',\n",
       " 'sentence',\n",
       " '.',\n",
       " '[SEP]',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'second',\n",
       " 'one',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763db423-8d60-4b81-bab7-d311b2092e2a",
   "metadata": {},
   "source": [
    "> model expects the inputs to be of the form [CLS] sentence1 [SEP] sentence2 [SEP] when there are two sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de04d3e3-d5b8-46a5-9cb0-b6b1bd57a91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['[CLS]', 'this', 'is', 'the', 'first', 'sentence', '.', '[SEP]', 'this', 'is', 'the', 'second', 'one', '.', '[SEP]']   \n",
    "[      0,      0,    0,     0,       0,          0,   0,       0,      1,    1,     1,        1,     1,   1,       1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a72c0-a458-4712-8e81-754f39f3dad4",
   "metadata": {},
   "source": [
    "> donâ€™t need to worry about whether or not there are token_type_ids in your tokenized inputs: as long as you use the same checkpoint for the tokenizer and the model, everything will be fine as the tokenizer knows what to provide to its model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60655507-e9c4-4767-add6-12efc654d37c",
   "metadata": {},
   "source": [
    "Datasets from the ðŸ¤— Datasets library are Apache Arrow files stored on the disk, so you only keep the samples you ask for loaded in memory\n",
    "Dataset.map() method if more preprocessing done than just tokenization. applying a function on each element of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cfe8002-2a47-4cb8-971b-9c66522b51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"],example[\"sentence2\"],truncation=True)\n",
    "#takes a dictionary (like the items of our dataset) \n",
    "#returns a new dictionary with the keys input_ids, attention_mask, and token_type_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b17a419-3f09-4680-8de1-1c929926ff2e",
   "metadata": {},
   "source": [
    " batched=True in our call to map so the function is applied to multiple elements of our dataset at once, and not on each element separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5528206b-7990-47d2-b938-5e17650b1b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1473aa3c3de1450d99a2743806037e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d6a0f5fc6742868822adc34771bff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b946ff82ef4b8c8a4cf89a247c5505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset=raw_datasets.map(tokenize_function,batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f593b3-a019-4dda-b297-e4ef473c1d6e",
   "metadata": {},
   "source": [
    "multiprocessing when applying your preprocessing function with map() by passing along a num_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25e6e92-4d40-405b-b159-564b37855548",
   "metadata": {},
   "source": [
    "## Dynamic Padding\n",
    ">function that is responsible for putting together samples inside a batch is called a collate function(a DataLoader argument),  \n",
    ">Default function that will just convert your samples to PyTorch tensors and concatenate them (recursively if your elements are lists, tuples, or dictionaries)\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714bd89-ebcc-4b01-9031-53f0d0f82fdd",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "- Variable Input Sizes due to Postponed Padding\n",
    "- Apply Padding as Necessary(diff batches have diff max length)\n",
    "- Speeds up Training\n",
    "- Potential Issues with TPUs and Variable Shapes\n",
    "-  we have to define a collate function that will apply the correct amount of padding to the items of the dataset we want to batch together.\n",
    "-   ðŸ¤— Transformers library provides us with such a function via DataCollatorWithPadding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a95f5bc1-31b9-4f65-91a3-2164935e3ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator=DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c688a9db-857b-4ef3-ac15-09acad850751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " \"Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .\",\n",
       " 'They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .',\n",
       " 'Around 0335 GMT , Tab shares were up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .',\n",
       " 'The stock rose $ 2.11 , or about 11 percent , to close Friday at $ 21.51 on the New York Stock Exchange .',\n",
       " 'Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier .',\n",
       " 'The Nasdaq had a weekly gain of 17.27 , or 1.2 percent , closing at 1,520.15 on Friday .',\n",
       " 'The DVD-CCA then appealed to the state Supreme Court .']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = tokenized_dataset[\"train\"][:8]\n",
    "samples['sentence1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d50406d4-09e4-429b-af3e-d1c1440732a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 59, 47, 67, 59, 50, 62, 32]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples={k: v for k,v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]}\n",
    "[len(x) for x in samples[\"input_ids\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c89e8-319e-416f-bf24-2a93675d12ef",
   "metadata": {},
   "source": [
    "> Dynamic padding means the samples in this batch should all be padded to a length of 67, the maximum length inside the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d52dbd6-1992-45df-9616-cdd09307737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([8, 67]),\n",
       " 'token_type_ids': torch.Size([8, 67]),\n",
       " 'attention_mask': torch.Size([8, 67]),\n",
       " 'labels': torch.Size([8])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator(samples)\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d4071-b8a2-4d15-88f0-4c49dab6319d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
