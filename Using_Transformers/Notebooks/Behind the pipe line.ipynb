{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40cb4fe-1281-4d13-ad4e-1fae6c677d30",
   "metadata": {},
   "source": [
    "# Behind the Pipe Line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a7a9d6-954d-4453-9a34-22edd90e7511",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcc60d4-f931-43ee-b34e-614dfe6a2010",
   "metadata": {},
   "source": [
    "![](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4419993-e8a5-4102-9961-dc004ef730c7",
   "metadata": {},
   "source": [
    "Transformer models canâ€™t process raw text directly  \n",
    "1.Splitting the input into words, subwords, or symbols (like punctuation) that are called tokens  \n",
    "2.Mapping each token to an integer  \n",
    "3.Adding additional inputs that may be useful to the model    \n",
    "\n",
    "All this preprocessing needs to be done in exactly the same way as when the model was pretrained,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1cec64-5171-4a2e-ad02-f1f1316a06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7701a2c1-37c1-472a-bad5-ab3d8d0974ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab27bf-0942-4463-8c3b-2e33d915a666",
   "metadata": {},
   "source": [
    ">we can directly pass our sentences to it and weâ€™ll get back a dictionary thatâ€™s ready to feed to our model!  \n",
    ">Transformer models only accept tensors as input  \n",
    "> You can pass one sentence or a list of sentences, as well as specifying the type of tensors you want to get back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f7c5903-8d53-457b-8792-ec41899d902b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2026,  2878,  2166,  1012,   102],\n",
      "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "\n",
    "inputs=tokenizer(raw_inputs,padding=True,truncation=True,return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b166c4dd-aac4-451b-b563-09c5152a89d4",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "253bc1ac-a246-4284-8a68-4bb778530003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "model=AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdea2da-534f-402b-ba0c-c12deb837572",
   "metadata": {},
   "source": [
    ">We can download our pretrained model the same way we did with our tokenizer. ðŸ¤— "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814fedec-e48d-4a6d-91ab-5161552b9141",
   "metadata": {},
   "source": [
    "### Hidden States"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1137b-1c1b-4507-acd1-e23c31fbcfcb",
   "metadata": {},
   "source": [
    "This architecture contains only the base Transformer module: given some inputs, it outputs what weâ€™ll call hidden states, also known as features. For each model input, weâ€™ll retrieve a high-dimensional vector representing the contextual understanding of that input by the Transformer model  \n",
    "like full model=transformer + head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6174f-9ecd-4ad9-b750-854008c5569d",
   "metadata": {},
   "source": [
    "The vector output by the Transformer module is usually large. It generally has three dimensions:\n",
    "\n",
    "**Batch size**: The number of sequences processed at a time (2 in our example).  \n",
    "**Sequence length**: The length of the numerical representation of the sequence (16 in our example).  \n",
    "**Hidden size**: The vector dimension of each model input. (its the  hyper-parameter that we choose during word to vec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5565cea-c53e-4b87-b156-f76275ff234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ca6bdf9-1f30-4bc5-bd46-ac4e5707da0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 768])\n"
     ]
    }
   ],
   "source": [
    "print(output.last_hidden_state.shape)\n",
    "#(You can access the elements by attributes (like we did) \n",
    "#or by key (outputs[\"last_hidden_state\"]), or even by index if you know exactly where the thing you are looking for is (outputs[0])."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f913143e-69f2-405d-8b54-7a1573597497",
   "metadata": {},
   "source": [
    "![](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7290c461-0e07-4eb0-9305-9c49820bc53e",
   "metadata": {},
   "source": [
    ">The model heads take the high-dimensional vector of hidden states as input and project them onto a different dimension. They are usually composed of one or a few linear layers\n",
    ">The embeddings layer converts each input ID in the tokenized input into a vector that represents the associated token.  \n",
    ">The subsequent layers manipulate those vectors using the attention mechanism to produce the final representation of the sentences.  \n",
    ">Each one designed around tackling a specific task. Here is a non-exhaustive list:\n",
    ">*ForMultipleChoice  \n",
    "*ForQuestionAnswering  \n",
    "*ForSequenceClassification  \n",
    "*ForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e58d1112-f8a6-4982-b0be-c9b00e9d8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82d82035-89e0-4ede-b75b-b2507d85b1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba710f67-5dfc-458f-b2a0-0f73fd3e4e78",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b1ab9a9-9675-43a0-9572-9aaa42abcb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5607,  1.6123],\n",
       "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits#(raw logits by last layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc0ad0-d096-4045-b1d2-a779785076b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "prediction=torch.nn.functional.softmax(outputs.logits,dim=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
